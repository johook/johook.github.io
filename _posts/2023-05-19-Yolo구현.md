# 우분투 환경

1. 환경구축
    
    우분투 20.04
    
    NVIDIA 53.0.41.03
    
    CUDA 12.1
    
    CUDNN 8.9.0
    

[Ubuntu 20.04에 CUDA Toolkit 11.2, cuDNN 8.1.0, Tensorflow 설치하기](https://webnautes.tistory.com/1428)

1. yolov5 gitclone 으로 불러오기
    
    ```python
    git clone https://github.com/ultralytics/yolov5.git
    ```
    
2. roboflow에서 dataset 받아오기
3. requirements.txt 라이브러리 및 의존성 패키지 설치해주기
    
    ```python
    pip install -r requirements.txt
    ```
    
4. dataset에 data.yaml 수정하기(yolov5 dir에서 모델을 돌리기 때문에 그 위치부터 시작되는 곳의 경로를 집어넣기 나같은 경우는 /home/jo/object_detection/yolov5/dataset 에 train,valid,test이미지가 있기 때문에 경로를 ./dataset/train/images 와 ./dataset/valid/images로 설정해주었다.)
    
    [data.yaml](%E1%84%8B%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%90%E1%85%AE%20%E1%84%92%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%20243103949be34856ae0af5c46459864d/data.yaml)
    
5. 모델의 크기 l,m,s,x 중 하나를 골라 train을 해준다. 
    1. 내 노트북 사양은 배치크기를 16으로 하면  
        
        Traceback (most recent call last):
        File "[train.py](http://train.py/)", line 642, in <module>
        main(opt)
        File "[train.py](http://train.py/)", line 531, in main
        train(opt.hyp, opt, device, callbacks)
        File "[train.py](http://train.py/)", line 312, in train
        pred = model(imgs)  # forward
        File "/home/jo/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
        File "/home/jo/object_detection/yolov5/models/yolo.py", line 209, in forward
        return self._forward_once(x, profile, visualize)  # single-scale inference, train
        File "/home/jo/object_detection/yolov5/models/yolo.py", line 121, in _forward_once
        x = m(x)  # run
        File "/home/jo/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
        File "/home/jo/object_detection/yolov5/models/common.py", line 56, in forward
        return self.act([self.bn](http://self.bn/)(self.conv(x)))
        File "/home/jo/.local/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
        return forward_call(*args, **kwargs)
        File "/home/jo/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 463, in forward
        return self._conv_forward(input, self.weight, self.bias)
        File "/home/jo/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
        return F.conv2d(input, weight, bias, self.stride,
        torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.81 GiB total capacity; 2.35 GiB already allocated; 19.69 MiB free; 2.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
        
        이런 CUDA가 메모리를 모두 사용하여 추가로 할당할 수 없기 때문에 발생하는 "CUDA out of memory" 오류가 떠서 배치 사이즈를 8로 줄였고 
        
    2. 모델을 large로 돌렸더니 
        
        File "/home/jo/object_detection/yolov5/utils/torch_utils.py", line 262, in fuse_conv_and_bn fusedconv.weight.copy_([torch.mm](http://torch.mm/)(w_bn, w_conv).view(fusedconv.weight.shape)) RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
        
        이런 오류가 발생하여 찾아보니 모델 사이즈를 줄이라는 조언이 있어서 모델을 small, medium으로 줄여서 돌렸을 때는 발생하지않았다.
        
    
6. train된 가중치 test.pt를 사용하여 test image를 detect한다.
7. -source 를 바꾸어가며 여러가지를 detect해본다
    
    
    ![00dea1edf14f09ab_jpg.rf.KJ730oDTFPdXdJxvSLnX.jpg](%E1%84%8B%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%90%E1%85%AE%20%E1%84%92%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%20243103949be34856ae0af5c46459864d/00dea1edf14f09ab_jpg.rf.KJ730oDTFPdXdJxvSLnX.jpg)
    
    ![08c8b73e0c2e296e_jpg.rf.effa65856584463c08848031cab357b9.jpg](%E1%84%8B%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%90%E1%85%AE%20%E1%84%92%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%20243103949be34856ae0af5c46459864d/08c8b73e0c2e296e_jpg.rf.effa65856584463c08848031cab357b9.jpg)
    
    ![video-_online-video-cutter.com_.gif](%E1%84%8B%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%90%E1%85%AE%20%E1%84%92%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%20243103949be34856ae0af5c46459864d/video-_online-video-cutter.com_.gif)
    
    ![video-_online-video-cutter.com_-_1_.gif](%E1%84%8B%E1%85%AE%E1%84%87%E1%85%AE%E1%86%AB%E1%84%90%E1%85%AE%20%E1%84%92%E1%85%AA%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%20243103949be34856ae0af5c46459864d/video-_online-video-cutter.com_-_1_.gif)